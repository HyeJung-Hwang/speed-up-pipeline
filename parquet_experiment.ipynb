{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import boto3\n",
    "import dotenv\n",
    "\n",
    "from s3 import upload_file_to_s3,download_file_from_s3\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv_file = dotenv.find_dotenv()\n",
    "dotenv.load_dotenv(dotenv_file)\n",
    "\n",
    "AWS_REGION_NAME = os.environ[\"AWS_REGION_NAME\"]\n",
    "AWS_ACCESS_KEY_ID = os.environ[\"AWS_ACCESS_KEY_ID\"]\n",
    "AWS_SECRET_ACCESS_KEY = os.environ[\"AWS_SECRET_ACCESS_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download CSV and Parquet file from AWS S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "csv_file_path = \"./amazonReivew.csv\"\n",
    "bucket = \"amazon-review-bucket\"\n",
    "key = \"amazonReview.csv\"\n",
    "local_destination = \"./amazonReview.csv\"\n",
    "\n",
    "download_file_from_s3(bucket, key, local_destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parquet_file_path = \"./amazonReivew.parquet\"\n",
    "bucket = \"amazon-review-bucket\"\n",
    "key = \"amazonReview.parquet\"\n",
    "local_destination = \"./amazonReview.parquet\"\n",
    "\n",
    "download_file_from_s3(bucket, key, local_destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compare file size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_file_size = os.path.getsize('./amazonReview.parquet') \n",
    "print('Parquet File Size:', parquet_file_size, 'bytes')\n",
    "csv_file_size = os.path.getsize('./amazonReview.csv') \n",
    "print('CSV File Size:', csv_file_size, 'bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Connect Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compare Read Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "csv_df = spark.read.format('csv') \\\n",
    "                .option('header','true') \\\n",
    "                .load(\"./amazonReview.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "parquet_df = spark.read.parquet(\"./amazonReview.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compare Count Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(csv_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(parquet_df.count())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
